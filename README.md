# Goldbull AI Model Suite

A family of efficient, lightweight AI models designed for CPU execution with <2GB memory footprint.

## Overview

The Goldbull AI Model Suite consists of specialized models for different AI tasks:

- **goldbull-text**: NLP Text Generation
- **goldbull-code**: Code Completion
- **goldbull-sage**: Question Answering
- **goldbull-brief**: Summarization
- **goldbull-vision**: Computer Vision
- **goldbull-multimodel**: Multimodal AI
- **goldbull-embedding**: Embedding Generator

## Key Features

- âœ… **CPU-Optimized**: Designed for efficient CPU execution
- âœ… **Memory Efficient**: <2GB memory footprint
- âœ… **Real-time Inference**: Optimized for fast CPU inference
- âœ… **32K Sequence Length**: Support for long sequences
- âœ… **TikToken Tokenizer**: Unicode-aware BPE tokenization
- âœ… **Multilingual**: 1M vocabulary from BPEmb
- âœ… **Function Calling**: External tool and API integration
- âœ… **Multiple Inference**: llama.cpp and ONNX support

## Architecture

### Core Components

- **goldbull-core**: Base model architecture and tensor operations
- **goldbull-tokenizer**: TikToken-style BPE tokenizer with Unicode support

### Specialized Models

Each model is optimized for its specific task while maintaining the core efficiency characteristics.

## Quick Start

```bash
# Build the entire workspace
cargo build --workspace

# Check all crates
cargo check --workspace

# Run tests
cargo test --workspace
```

## Model Specifications

| Component | Status | Memory | Features |
|-----------|---------|---------|----------|
| Core Library | âœ… | <500MB | Base architecture, tensor ops |
| Tokenizer | âœ… | <100MB | BPE, Unicode, 1M vocab |
| Text Model | ðŸ”„ | <2GB | Text generation |
| Code Model | ðŸ”„ | <2GB | Code completion |
| Sage Model | ðŸ”„ | <2GB | Question answering |
| Brief Model | ðŸ”„ | <2GB | Summarization |
| Vision Model | ðŸ”„ | <2GB | Computer vision |
| Multimodel | ðŸ”„ | <2GB | Multimodal AI |
| Embedding | ðŸ”„ | <2GB | Embeddings |

## Development

This project is implemented in Rust for maximum performance and safety. The codebase follows a modular architecture with clear separation of concerns.

### Project Structure

```
goldbull-ai/
â”œâ”€â”€ goldbull-core/          # Base model architecture
â”œâ”€â”€ goldbull-tokenizer/     # TikToken-style tokenizer
â”œâ”€â”€ goldbull-text/          # Text generation model
â”œâ”€â”€ goldbull-code/          # Code completion model
â”œâ”€â”€ goldbull-sage/          # Question answering model
â”œâ”€â”€ goldbull-brief/         # Summarization model
â”œâ”€â”€ goldbull-vision/        # Computer vision model
â”œâ”€â”€ goldbull-multimodel/    # Multimodal model
â”œâ”€â”€ goldbull-embedding/     # Embedding model
â”œâ”€â”€ goldbull-training/      # Training utilities
â””â”€â”€ goldbull-inference/     # Inference engines
```

## License

MIT License - see LICENSE file for details.